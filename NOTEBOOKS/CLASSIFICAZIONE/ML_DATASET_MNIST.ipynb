{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b44e1ab8",
      "metadata": {
        "id": "b44e1ab8"
      },
      "source": [
        "### **MNIST**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA8kAYwzLmpV"
      },
      "source": [
        "### **LIBRERIE & IMPORT**"
      ],
      "id": "TA8kAYwzLmpV"
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q tensorflow"
      ],
      "metadata": {
        "id": "o_XxLgjF0T3Z"
      },
      "id": "o_XxLgjF0T3Z",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8e478984"
      },
      "outputs": [],
      "source": [
        "# Librerie\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import tensorflow\n",
        "\n",
        "################ SOLO SU VS CODE ##################\n",
        "#Funzione di plotting\n",
        "# import os, sys\n",
        "#sys.path.append(os.path.abspath(\"..\"))\n",
        "# from FUNCTIONS.utils import <nome-funzione>\n",
        "###################################################\n",
        "\n",
        "# Funzione che serve ad effettuare la divisione tra train set e test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Metriche per definire la qualità del modello generato\n",
        "from sklearn.metrics import accuracy_score #, mean_squared_error, classification_report\n",
        "# Caricamento Dati\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.datasets import load_digits\n",
        "# Per Scaling dei dati\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# SVM\n",
        "from sklearn.svm import SVC\n",
        "# KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# K-MEANS\n",
        "from sklearn.cluster import KMeans\n",
        "# NEURAL NETWORK RELU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "id": "8e478984"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **DATASET MNIST**"
      ],
      "metadata": {
        "id": "WBUUvuqI4Jtt"
      },
      "id": "WBUUvuqI4Jtt"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# Versione completa, 28x28\n",
        "mnist = fetch_openml('mnist_784')\n",
        "# Versione ridotta, 8x8\n",
        "# mnist = load_digits()\n",
        "\n",
        "X, y = mnist.data, mnist.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = RANDOM_SEED)\n",
        "\n",
        "# Normalizzo i dati applicando lo scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "N36QGyG44DWu"
      },
      "id": "N36QGyG44DWu",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ACCURACY**"
      ],
      "metadata": {
        "id": "DB7u9vJui1sU"
      },
      "id": "DB7u9vJui1sU"
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = {\n",
        "    \"Decision Tree\" : DecisionTreeClassifier(),\n",
        "    \"Regressione Logistica\" : LogisticRegression(max_iter=10000),\n",
        "    \"SVM\" : SVC(),\n",
        "    \"KNN\" : KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "for name, model in classifiers.items():\n",
        "    start = time.time()\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    end = time.time()\n",
        "    accuracy_mnist = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name} accuracy: {accuracy_mnist*100:.2f}% ({end-start:.2f}s)\")"
      ],
      "metadata": {
        "id": "WUGYI-Adl_9l",
        "outputId": "e829d832-4679-412a-d696-38f6fd0b1f4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WUGYI-Adl_9l",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree accuracy: 87.27% (25.38s)\n",
            "Regressione Logistica accuracy: 91.54% (65.17s)\n",
            "SVM accuracy: 96.30% (675.94s)\n",
            "KNN accuracy: 94.58% (77.28s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **RETE NEURALE - MNIST**"
      ],
      "metadata": {
        "id": "S6WyXqfVmAxh"
      },
      "id": "S6WyXqfVmAxh"
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28,28)),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dropout(0.2),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(X_train_scaled, y_train_cat, epochs=10, batch_size=32, verbose=0)\n",
        "loss, nn_accuracy = model.evaluate(X_test_scaled, y_test_cat, verbose=0)\n",
        "end = time.time()\n",
        "print(f\"Neural Network accuracy: {nn_accuracy*100:.2f}% ({end-start:.2f}s)\")"
      ],
      "metadata": {
        "id": "7djBcS4Ni5JA",
        "outputId": "38283d23-465b-46d1-da36-996cdc05e0e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "id": "7djBcS4Ni5JA",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(32, 784), dtype=float32). Expected shape (None, 28, 28), but input has incompatible shape (32, 784)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 784), dtype=float32)\n  • training=True\n  • mask=None\n  • kwargs=<class 'inspect._empty'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2196481272.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36m_adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    274\u001b[0m                     \u001b[0madjusted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;34mf\"Invalid input shape for input {x}. Expected shape \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;34mf\"{ref_shape}, but input has incompatible shape {x.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(32, 784), dtype=float32). Expected shape (None, 28, 28), but input has incompatible shape (32, 784)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 784), dtype=float32)\n  • training=True\n  • mask=None\n  • kwargs=<class 'inspect._empty'>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CONSIDERAZIONI**"
      ],
      "metadata": {
        "id": "yRwjYCtd1pG4"
      },
      "id": "yRwjYCtd1pG4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**optimizer=\"adam\"** => Algoritmo di ottimizzazione che aggiorna i pesi durante l'allenamento (Adam è molto efficiente)\n",
        "\\\n",
        "**loss=\"categorical_crossentropy\"** => Funzione di perdita per problemi di classificazione multi-classe (abbiamo 10 classi)\n",
        "\\\n",
        "**metrics=[\"accuracy\"]** => Metrica da monitorare durante l'allenamento (visualizzi l'accuracy ad ogni epoca)\n",
        "\\\n",
        "\n",
        "**1. to_categorical()**    → Trasforma label in one-hot (3 → [0,0,0,1,0,0,0,0,0,0])\n",
        "\\\n",
        "**2. Flatten()**           → Converte 28x28 in vettore di 784\n",
        "\\\n",
        "**3. Dense(128, relu)**    → Hidden layer con 128 neuroni\n",
        "\\\n",
        "**4. Dropout(0.2)**        → Disattiva 20% per evitare overfitting\n",
        "\\\n",
        "**5. Dense(10, softmax)**  → Output con 10 neuroni (probabilità per ogni cifra)\n",
        "\\\n",
        "**6. compile()**           → Configura optimizer, loss, metrics\n",
        "\\\n",
        "**7. fit()**               → Allena il modello per 10 epochs\n",
        "\\\n",
        "**8. evaluate()**          → Valuta su dati di test\n",
        "\n",
        "**Dense** => layer connessi\n",
        "\\\n",
        "**Dropout** => previene overfitting\n",
        "\\\n",
        "**compile()** => configura come allenare\n",
        "\n",
        "**Due Dense:** *uno elabora (hidden) e uno classifica (output)*\n"
      ],
      "metadata": {
        "id": "oGkzxcQN1sCY"
      },
      "id": "oGkzxcQN1sCY"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}