{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Installer Librerie**"
      ],
      "metadata": {
        "id": "M8qqZKJ_YZx7"
      },
      "id": "M8qqZKJ_YZx7"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ed0f2c8b",
      "metadata": {
        "id": "ed0f2c8b"
      },
      "outputs": [],
      "source": [
        "# ! pip install -q tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install scikit-learn #Per Running Locale"
      ],
      "metadata": {
        "id": "j1sJDuWdYt3t"
      },
      "id": "j1sJDuWdYt3t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TEST**"
      ],
      "metadata": {
        "id": "l82UEQeUY1jc"
      },
      "id": "l82UEQeUY1jc"
    },
    {
      "cell_type": "code",
      "source": [
        "# ! nvidia-smi # For Show GPU Parameters"
      ],
      "metadata": {
        "id": "WqQ0JYLnvEBB"
      },
      "id": "WqQ0JYLnvEBB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hello\")"
      ],
      "metadata": {
        "id": "ObeyO230v7h2"
      },
      "id": "ObeyO230v7h2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **METRICHE**"
      ],
      "metadata": {
        "id": "jQ7Y322YZGtP"
      },
      "id": "jQ7Y322YZGtP"
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "# SET DATI\n",
        "gt = [1,1,0,0,0,1,1]\n",
        "pred = [1,1,1,0,0,0,1]\n",
        "\n",
        "# CLASSIFICAZIONE\n",
        "f1 = sklearn.metrics.f1_score(gt, pred)\n",
        "print(f\"\\nF1_Score: {f1}\")\n",
        "\n",
        "accuracy = round(sklearn.metrics.accuracy_score(gt, pred), 2)\n",
        "print(f\"\\nAccuracy: {accuracy}\")\n",
        "\n",
        "precision = sklearn.metrics.precision_score(gt, pred)\n",
        "print(f\"\\nPrecison: {precision}\")\n",
        "\n",
        "recall = sklearn.metrics.recall_score(gt, pred)\n",
        "print(f\"\\nRecall: {recall}\")\n",
        "\n",
        "# REGRESSIONE\n",
        "mean = round(sklearn.metrics.mean_absolute_error(gt, pred), 2)\n",
        "print(f\"\\nMean Absolute Error: {mean}\")\n",
        "\n",
        "mean_err = round(sklearn.metrics.mean_squared_error(gt, pred), 2)\n",
        "print(f\"\\nMean Squared Error: {mean_err}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc-sfbjYSokJ",
        "outputId": "7b3a8edc-411f-4e95-ff95-ab09739f00f1"
      },
      "id": "Sc-sfbjYSokJ",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "F1_Score: 0.75\n",
            "\n",
            "Accuracy: 0.71\n",
            "\n",
            "Precison: 0.75\n",
            "\n",
            "Recall: 0.75\n",
            "\n",
            "Mean Absolute Error: 0.29\n",
            "\n",
            "Mean Squared Error: 0.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PVlRwq5RYYjF"
      },
      "id": "PVlRwq5RYYjF",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}